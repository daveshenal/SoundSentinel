{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pydub import AudioSegment, silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TARGET_DURATION = 2.5 * 1000  # 2.5 seconds in milliseconds\n",
    "MINIMUM_AUDIO_DURATION = 1000  # minimum after silence removal (gun,glass-400 scream-300 neutral-1s)\n",
    "SILENCE_THRESHOLD = -40  # dB  (gun,glass-35 scream-30)\n",
    "MAX_SILENCE_DURATION = 200 # 500\n",
    "OVERLAP_RATIO = 0.25\n",
    "SAMPLE_RATE = 22050  # 16 kHz\n",
    "OUTPUT_DIR = \"../data/proccessed/processed_dataset\"\n",
    "INPUT_DIR = \"../data/raw/dataset\"\n",
    "\n",
    "class_names = ['glass_break', 'gunshot', 'scream', 'neutral']\n",
    "\n",
    "# Ensure output directory exists\n",
    "for class_name in class_names:\n",
    "    os.makedirs(f\"{OUTPUT_DIR}/{class_name}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(file_path, output_path):\n",
    "    # Step 1: Load audio using librosa\n",
    "    audio, sr = librosa.load(file_path, sr=SAMPLE_RATE)  # Loads and resamples\n",
    "    original_duration = len(audio) / sr * 1000  # Original duration in ms\n",
    "    \n",
    "    # Convert librosa audio back to AudioSegment for silence detection\n",
    "    audio = AudioSegment(\n",
    "        (audio * 32767).astype(np.int16).tobytes(),\n",
    "        frame_rate=SAMPLE_RATE,\n",
    "        sample_width=2,\n",
    "        channels=1\n",
    "    )\n",
    "       \n",
    "    # Step 1: Remove silence\n",
    "    non_silent_chunks = silence.detect_nonsilent(\n",
    "        audio, min_silence_len=MAX_SILENCE_DURATION, silence_thresh=SILENCE_THRESHOLD\n",
    "    )\n",
    "    trimmed_audio = AudioSegment.silent(0)\n",
    "    for start, end in non_silent_chunks:\n",
    "        trimmed_audio += audio[start:end]\n",
    "\n",
    "    # Ensure the audio has at least 1500 ms after silence removal\n",
    "    if len(trimmed_audio) < MINIMUM_AUDIO_DURATION:\n",
    "        # print(f\"Audio is too short after silence removal. file path: {file_path}\")\n",
    "        return 0, original_duration, len(trimmed_audio)\n",
    "    \n",
    "    # Step 2: Ensure 22050 kHz sample rate\n",
    "    samples = np.array(trimmed_audio.get_array_of_samples())\n",
    "    resampled_audio = librosa.resample(samples.astype(float), \n",
    "                                       orig_sr=trimmed_audio.frame_rate, \n",
    "                                       target_sr=SAMPLE_RATE)\n",
    "    \n",
    "    # Convert resampled audio to AudioSegment\n",
    "    resampled_audio = AudioSegment(\n",
    "        resampled_audio.astype(np.int16).tobytes(), frame_rate=SAMPLE_RATE,\n",
    "        sample_width=2, channels=1\n",
    "    )\n",
    "\n",
    "    # Step 3: Chunk or pad audio to 2.5 seconds\n",
    "    duration = len(resampled_audio)  # Duration in milliseconds\n",
    "    chunks = []\n",
    "    \n",
    "    if duration > TARGET_DURATION:\n",
    "        step = int(TARGET_DURATION * (1 - OVERLAP_RATIO))\n",
    "        for i in range(0, int(duration - TARGET_DURATION + step), step):\n",
    "            chunks.append(resampled_audio[i:i + TARGET_DURATION])\n",
    "            \n",
    "        # Removing the last chunk to make sure all the cunks are 2.5 seconds   \n",
    "        chunks.pop()   \n",
    "\n",
    "        \n",
    "    else:\n",
    "        # If 2.5s > audio duration > 1.5s, add padding\n",
    "        padding_needed = TARGET_DURATION - duration\n",
    "        padding_start = AudioSegment.silent(duration=padding_needed // 2)\n",
    "        padding_end = AudioSegment.silent(duration=padding_needed - len(padding_start))\n",
    "        padded_audio = padding_start + resampled_audio + padding_end\n",
    "        chunks.append(padded_audio)   \n",
    "    \n",
    "    # Save chunks\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk.export(\n",
    "            os.path.join(output_path, f\"{base_name}_chunk_{i + 1}.wav\"),\n",
    "            format=\"wav\"\n",
    "        )\n",
    "    return len(chunks), original_duration, len(trimmed_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all audio files in a directory\n",
    "def process_dataset(input_dir, output_path, class_name):\n",
    "    # Get a list of all the audio files in the directory\n",
    "    audio_files = [f for f in os.listdir(input_dir) if f.endswith((\".wav\", \".mp3\"))]\n",
    "    \n",
    "    # Use tqdm for progress bar\n",
    "    for file_name in tqdm(audio_files, desc=f\"Processing files in {class_name}\", unit=\"file\", ncols=100):\n",
    "        file_path = os.path.join(input_dir, file_name)\n",
    "        \n",
    "        # Call the function to preprocess the audio file\n",
    "        num_chunks, orig_duration, trimmed_duration = preprocess_audio(file_path, output_path)\n",
    "        \n",
    "        # print(f\"Processed {file_name}:\")\n",
    "        # print(f\"  - Original Duration: {orig_duration / 1000:.2f}s\")\n",
    "        # print(f\"  - Trimmed Duration: {trimmed_duration / 1000:.2f}s\")\n",
    "        # print(f\"  - Chunks Created: {num_chunks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files in glass_break: 100%|██████████████████████████| 335/335 [00:14<00:00, 23.18file/s]\n",
      "Processing files in gunshot: 100%|████████████████████████████| 1794/1794 [00:45<00:00, 39.31file/s]\n",
      "Processing files in scream: 100%|█████████████████████████████| 2232/2232 [01:08<00:00, 32.42file/s]\n",
      "Processing files in neutral: 100%|████████████████████████████| 2366/2366 [01:43<00:00, 22.88file/s]\n"
     ]
    }
   ],
   "source": [
    "for class_name in class_names:\n",
    "    input_path = f\"{INPUT_DIR}/{class_name}\"\n",
    "    output_path = f\"{OUTPUT_DIR}/{class_name}\"\n",
    "    process_dataset(input_path, output_path, class_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
